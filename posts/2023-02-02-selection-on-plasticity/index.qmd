---
title: "Validating a model of selection on plasticity"
author: "Andrew MacDonald"
description: |
  Plus Ã§a change, plus c'est la change qui change
date: 02 Feb 2023
categories: [UdeS, stan]
execute:
  eval: false
---

```{r setup, eval=TRUE, message=FALSE, warning=FALSE}
library(targets)
library(ggplot2)
library(tidyverse)
library(tidybayes)
```

when an animal shows a difference

All animals respond to the environment, adapting their physical or biological characteristics into

all an

the response that an animal has, is in part determined by heir genetics, by heritable variation in their ability

other factors can of course invluence who an animal responds to changing environment. It might be that animals only respond to changing environment when they are in good condition. or that changes in the environment always provoke differenc responses, but hat selection only happnens a few years out of the total

anyway, we are going to simulate data from a complex model of selection on two correlated traits.

let's start small

```{r}
# environment 
nindivid <- 38
neach <- 4

fake_obs <- expand_grid(indiv_id = rep(1:nindivid, each = neach)) |> 
  mutate(X = runif(length(indiv_id), min = 11, max = 26))

# slopes
slope_mean <- 2.6
slope_sd <- .9
b_1 <- rnorm(nindivid, mean = slope_mean, sd = slope_sd)
b_0 <- 3

fake_obs |> 
  mutate(b_0 = b_0,
         b_1 = b_1[indiv_id],
         y = b_0 + b_1 * X) |> 
  ggplot(aes(x = X, y = y, group = indiv_id)) + geom_line()

```

it's unlikely that everyone has the same yintercept

a different approach, based on group-mean centering, will help us think about this

```{r}
b_0 <- rnorm(nindivid, mean = 45, sd = 6)
fake_obs_2par <- fake_obs |> 
  group_by(indiv_id) |> 
  mutate(x_c = X - mean(X), 
         y = b_0[indiv_id] + b_1[indiv_id] * x_c)

fake_obs_2par |> 
  ggplot(aes(x = X, y = y, group = indiv_id)) + geom_line()

```

contrast this with the display for the centered variable

```{r}
fake_obs_2par |> 
  ggplot(aes(x = x_c, y = y, group = indiv_id)) + geom_line()
```

this is just a simple demo of a pretty general pattern!

centering just moves the line around -- I think we would model this this way, if we felt that the

let's start simulating data and comparing the fit with models

```{r}
sd_obs <- 3
fake_obs_error <- fake_obs_2par |> 
  mutate(yobs = rnorm(n = length(y), mean = y, sd = sd_obs))

fake_obs_error |> 
  ggplot(aes(x = X, y = yobs)) + 
  geom_point()
```

We can already try to model this

```{r}
library(lme4)

m <- lmer(yobs ~ X + (X|indiv_id), data = fake_obs_error)

m |> summary()
```

works but not really helpful for the intercepts -- we need to fit a centered model to get those values:

```{r}
lmer(yobs ~ x_c + (x_c|indiv_id), data = fake_obs_error) |> 
  summary()
```

Now we can recover parameters that went in to the model.

## two correlated predictors

This will come together with the rest of the model soon, but I want to get a start on this now. The two traits we are mesauring are kind of weird and different from the tutal way of thinking about environemtnal traits. let me try to explain it. so there was another procedure earlier which attempted to measure the "window" of temperature which provokes the greatest change.

as an aside, do we expect the greatest variation to be found with the greatest selection? consider the number of adjectives in a scientivi paper vs the number of refrerences. I don't know, but I would epect that the former is way more variable -- and matters far less.

anyway that was done. So the two response variables here are measured in the same units but not exactly the same VALUES for each

just makes me curious to start by simulating this (and perhaps also to look in the data for examples)

```{r}
tibble(orig = rerun(350, runif(30, min = -1, max = 1))) |> 
  rowwise() |> 
  mutate(x1 = mean(head(orig, 21)),
         x2 = mean(tail(orig, 21))) |> 
  ggplot(aes(x = x1, y = x2)) + geom_point()
```

Sure enough they are correlated. I'm sure with some effort I could calculate the equation for this correlation, but let's not.

Did audrey do this differently for each bird? for each environmental variable or what? does it count as conditioning?

TK ask her this question.

## back to main question: measuring selection

lets begin by replicating the bivariate model of fitness that you see, for example, in

start with fake obs eror

```{r}
# environment 
nindivid <- 38
neach <- 4

fake_obs <- expand_grid(indiv_id = rep(1:nindivid, each = neach)) |> 
  mutate(X = runif(length(indiv_id), min = 11, max = 26))

# slopes
slope_mean <- 2.6
slope_sd <- .9
intercept_mean <- 45
intercept_sd <- 6
b_1 <- rnorm(nindivid, mean = slope_mean, sd = slope_sd)
b_0 <-  rnorm(nindivid, mean = slope_mean, sd = slope_sd)

fake_obs |> 
  mutate(b_0 = b_0,
         b_1 = b_1[indiv_id],
         y = b_0 + b_1 * X)
```

```{r}
fake_obs_error
```
