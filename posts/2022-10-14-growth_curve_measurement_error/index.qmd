---
title: "Growth curves"
author: "Andrew"
date: "2022-10-14"
categories: [stan, simulation]
image: gq_fig-1.png
execute: 
  warning: false
---

```{r eval=TRUE, message=FALSE, warning=FALSE}
library(targets)
library(ggplot2)
library(tidyverse)
library(tidybayes)
suppressPackageStartupMessages(library(cmdstanr))
```

Many animals and plants grow quickly when small and more slowly as they mature. There are many popular ways of describing this relationship; one very common and convenient relationship is the Von-Bertanalaffy (VB) growth curve:

$$
L_t = L_0e^{-rt} + L_\infty(1 - e^{-rt})
$$ {#eq-vb}

This can also be written as

$$
L_t = L_\infty - (L_\infty - L_0)e^{-rt}
$$

This curve has a long tradition in ecology. It can be derived from simple assumptions about how different aspects of metabolism scale with the body size of an organism. I'm not going to derive it here because I don't want this to be a huge post!

I like this second way of writing the equation because it highlights that the VB equation is a linear transformation of an exponential function. We start out at $L_0$ and exponentially decay towards $L_\infty$.

## a single tree

I'm going to do a simple simulation of one tree growing. here is code that does that

```{r }
sim_vb_one_tree <- function(
    time = seq(from = 10, to = 200, by = 5),
    Lo = .01,
    Lmax = 150,
    r = .03,
    sd = 5){
  tibble::tibble(time,
                 Lt = Lmax - (Lmax - Lo) * exp(-r*time),
                 Lt_obs  = rnorm(length(Lt),
                                 mean = Lt,
                                 sd = 5))
}

vb_one_tree <- sim_vb_one_tree()

vb_one_tree |> 
  ggplot(aes(x = time, y = Lt_obs)) + 
  geom_point() + 
  geom_line(aes(y = Lt)) + 
  theme_bw()
```

## Recover parameters

Here is a stan model that matches this data generating process:

```{r}
#| echo: FALSE
#| class.output: stan
vb_one_tree <- cmdstan_model(
  here::here("posts/2022-10-14-growth_curve_measurement_error/vb_one_tree.stan"))

vb_one_tree
```

```{r, warning=FALSE, message=FALSE}

one_tree_sim <- sim_vb_one_tree(
    Lmax = 150,
    r = .03,
    sd = 5)

one_tree_list <- list(n = nrow(one_tree_sim),
                      time  = one_tree_sim$time, 
                      Lt = one_tree_sim$Lt_obs)

one_tree_post <- vb_one_tree$sample(data = one_tree_list,
                                    refresh = 0L,
                                    parallel_chains = 4)

one_tree_post$summary() |> 
  knitr::kable()
```

These posterior intervals cover the numbers used to make up the data pretty well! Let's look at the model predictions on a figure:

```{r}
#| fig-cap: Growth curve for one tree. the line shows the expected value, with posterior uncertainty around exactly what that average should be. 

expected_df <- one_tree_post |> 
  spread_rvars(Lmax, r) |> 
  expand_grid(time = seq(0, 200, length.out = 14)) |> 
  mutate(Lt = Lmax * (1 - exp(-r * time)))

expected_plot <- expected_df |> 
  ggplot(aes(x = time, ydist = Lt)) + 
  stat_dist_lineribbon()

expected_plot
```

This relationship shows the *average* line, the expected size of the tree. We can add the original data like this:

```{r}
one_tree_sim |> 
  ggplot(aes(x = time, y = Lt_obs)) + 
  geom_point() +
  stat_dist_lineribbon(aes(x = time, dist = Lt),
                  data = expected_df, inherit.aes = FALSE) + 
  theme_bw()
```

At the time of this writing the error messages here are particularly unhelpful. If you try to use `stat_lineribbon` rather than `stat_dist_lineribbon` you get the following misleading message:

```{r error=TRUE, eval=TRUE}
one_tree_sim |> 
  ggplot(aes(x = time, y = Lt_obs)) + 
  geom_point() +
  stat_lineribbon(aes(x = time, y = Lt),
                  data = expected_df, inherit.aes = FALSE)
```

## Adding measurement error

The above model reproduces predictions of the original line, but ignores measurement error. Here's a few ways to add that into this same approach:

### Simulating observations in R

One way to do this is after the fact, using the handy tidyverse `dplyr::rowwise()` syntax, combined with `posterior::rfun()`. The latter function transforms `rnorm` into a function that both takes and produces an `rvar`, the specialized format for working with posterior draws. The latter function makes sure we redo this for every row of our dataframe.

```{r}
expected_df <- one_tree_post |> 
  spread_rvars(Lmax, r, sigma_obs) |> 
  expand_grid(time = seq(0, 200, length.out = 14)) |> 
  mutate(Lt = Lmax * (1 - exp(-r * time))) |> 
  rowwise() |> 
  mutate(Lt_obs = posterior::rfun(rnorm)(n = 1, mean = Lt, sd = sigma_obs))

expected_df |> 
  ggplot(aes(x = time, dist = Lt_obs)) + 
  stat_lineribbon() + 
  scale_fill_brewer(palette = "Greens") + 
  geom_point(aes(y = Lt_obs), data = one_tree_sim,
             pch = 21, fill = "darkorange") + 
  theme_bw()
```

This has the advantage of happening all in R, keeping our posterior distribution slim.\
However sometimes it can be both convenient and more readable to keep the whole process inside Stan, and here's how:

### Posterior predictive simulations in Stan

```{r gq_demo}
#| class.output: stan
vb_one_tree_gq <- cmdstan_model(
  stan_file = here::here(
    "posts/2022-10-14-growth_curve_measurement_error/vb_one_tree_gq.stan"))

vb_one_tree_gq
```

```{r gq_fig, fig.path=""}
one_tree_predictions <- vb_one_tree_gq$sample(
  data = purrr::splice(one_tree_list,
                       time_new = seq(0, 200, length.out = 14),
                       n_new = 14),
  refresh = 0L,
  parallel_chains = 4)

one_tree_predictions |> 
  spread_rvars(Lt_predicted[i]) |> 
  mutate(time_new = seq(0, 200, length.out = 14)) |> 
  ggplot(aes(x = time_new, dist = Lt_predicted)) + 
  stat_lineribbon() +
  scale_fill_brewer(palette = "Greens") + 
  geom_point(aes(x = time, y = Lt_obs), 
             inherit.aes = FALSE,
             data = one_tree_sim,
             pch = 21, fill = "darkorange") + 
  theme_bw()
```
