{
  "hash": "d98ce26e9952f8af5981526b5557e678",
  "result": {
    "markdown": "---\ntitle: \"Missing data in non-normal distributions\"\nauthor: \"Andrew MacDonald, Flavio Affinito\"\ndescription: |\n  We could have counted them but we didn't.\ndate: 22 Aug 2023\ndraft: true\neditor: source\ncategories: [UdeS, stan, QCBS]\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(cmdstanr)\n```\n:::\n\n\n## working with missingness\n\nI wish the topic of missingness was introduced much earlier in statistical ecology! \nMost ecological datasets have some examples of this. \nWorking directly with missing data has many advantages, including letting us use ALL the information we have. There are many arguments, but that's the one I find most compelling. In our science, each datapoint costs dearly in money and effort -- the least we can do is learn the tools to use them well! \n\n## Roadmap\n\n1. normal distributions with missing data\n1. nonnormal distributions with missing data\n1. regression with missing information in just the x\n1. regression with missing data in both\n1. nonlinear, nonnormal missing data in both\n\n## Normal distributions with missing data\n\nHere is code from [Flavio Affinito](https://qcbs.ca/fr/membre-etudiant/?student=3066), adapting the code in the [Stan Guide](https://mc-stan.org/docs/stan-users-guide/sliced-missing-data.html) for continuous missing data: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMissingDataImputation2 <- cmdstanr::cmdstan_model(\n  here::here(\"posts/2023-08-24-imputation-nonnormal/MissingDataImputation2.stan\"))\nMissingDataImputation2\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> N_tot;          // Total number of observations\n  int<lower=0> N_miss;        // Number of missing values\n  int<lower=0> N_obs;        // Number of observed values\n  array[N_obs] int<lower=1, upper=N_tot> ii_obs;  // Position of observed values in the column\n  array [N_miss] int<lower=1, upper=N_tot> ii_mis; // Position of the missing values in the column\n  vector[N_obs] y_obs;            // Observed values\n  //int<lower=0> N_year;     // Number of years in the dataset\n}\n\n\nparameters {\n  real mu;              // Population mean\n  real<lower=0> sigma;     // Common standard deviation\n  vector[N_miss] y_imputed;       // Imputed outcomes for missing data\n}\n\ntransformed parameters {\n  vector[N_tot] y;      // create the dataset to fit the likelihood\n  y[ii_obs] = y_obs;        // assign observations to the positions with observations\n  y[ii_mis] = y_imputed;    // assign parameters (y missing) to the positions without observations\n}\n\nmodel {\n  // Priors\n  mu ~ normal(50, 10);\n  sigma ~ exponential(.1);\n\n  // Likelihood for observed and imputated data\n  y ~ normal(mu, sigma);\n}\n\ngenerated quantities {\n  vector[N_tot] y_pred;\n\n  for (i in 1:N_tot) {\n    y_pred[i] = normal_rng(mu, sigma);\n  }\n}\n```\n:::\n:::\n\n\nLet's try it out with 42 numbers, of which 6 are missing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nxx<- rnorm(42, mean = 50, sd = 10)\nxx2 <- xx\nxx2[sample(42, 6, replace = FALSE)] <- NA\n\nhist(xx2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_missing <- MissingDataImputation2$sample(\n  data = list(\n    N_tot = 42,\n    N_miss = 6,\n    N_obs = 42-6,\n    ii_obs = which(!is.na(xx2)),\n    ii_mis = which(is.na(xx2)),\n    y_obs = xx2[which(!is.na(xx2))]), \n  parallel_chains = 4,\n  refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.4 seconds.\nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.6 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_and_original <- normal_missing$draws() |> \n  gather_rvars(y_imputed[i]) |> \n  mutate(xx = xx[which(is.na(xx2))])\n\n\n\nlibrary(tidybayes)\nposterior_and_original |> \n  ggplot(aes(x = xx, ydist = .value)) + \n  stat_pointinterval()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0.\nâ„¹ Please use the `linewidth` aesthetic instead.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nunsurprisingly this is the same distribution for all parameters\n\n## with a linear relationship\n\nlet's imagine there is a clear linear relationship but we still have missing values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyy_bar <- 12 + 2*(xx - 50)\n\nyy <- rnorm(42, yy_bar, sd = 3)\n\nplot(xx, yy)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nwith the same 6 datapoints missing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregression_imputation <- cmdstanr::cmdstan_model(\n  here::here(\"posts/2023-08-24-imputation-nonnormal/regression_imputation.stan\"))\nregression_imputation\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> N_tot;          // Total number of observations\n  int<lower=0> N_miss;        // Number of missing values\n  int<lower=0> N_obs;        // Number of observed values\n  array[N_obs] int<lower=1, upper=N_tot> ii_obs;  // Position of observed values in the column\n  array [N_miss] int<lower=1, upper=N_tot> ii_mis; // Position of the missing values in the column\n  vector[N_obs] x_obs;            // Observed values\n  vector[N_tot] y;\n}\n\n\nparameters {\n  real x_mu;              // Population mean\n  real<lower=0> x_sigma;     // Common standard deviation\n  vector[N_miss] x_imputed;       // Imputed values for missing data\n  real slope;\n  real intercept;\n  real<lower=0> y_sigma;\n}\n\ntransformed parameters {\n  vector[N_tot] x;      // create the dataset to fit the likelihood\n  x[ii_obs] = x_obs;        // assign observations to the positions with observations\n  x[ii_mis] = x_imputed;    // assign parameters (y missing) to the positions without observations\n}\n\nmodel {\n  // Priors\n  x_mu ~ normal(50, 10);\n  x_sigma ~ exponential(.1);\n  intercept ~ normal(10, 4);\n  y_sigma ~ exponential(.1);\n\n  // Likelihood for observed and imputated data (x)\n  x ~ normal(x_mu, x_sigma);\n  // LIkelihood for the response variable\n  // y ~ normal(intercept + slope * (x - 50), y_sigma);\n  y ~ normal(intercept + slope * (x - x_mu), y_sigma);\n}\n\ngenerated quantities {\n  vector[N_tot] x_pred;\n\n  for (i in 1:N_tot) {\n    x_pred[i] = normal_rng(x_mu, x_sigma);\n  }\n}\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nregression_missing <- regression_imputation$sample(\n  data = list(\n    N_tot = 42,\n    N_miss = 6,\n    N_obs = 42 - 6,\n    ii_obs = which(!is.na(xx2)),\n    ii_mis = which(is.na(xx2)),\n    x_obs = xx2[which(!is.na(xx2))],\n    y = yy\n    ),\n  parallel_chains = 4,\n  refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.8 seconds.\nChain 4 finished in 0.7 seconds.\nChain 2 finished in 0.8 seconds.\nChain 3 finished in 0.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 0.9 seconds.\n```\n:::\n:::\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nposterior_and_original <- regression_missing$draws() |> \n  gather_rvars(x_imputed[i]) |> \n  mutate(xx = xx[which(is.na(xx2))],\n         yy = yy[which(is.na(xx2))]\n  )\n\n\nposterior_and_original |> \n  ggplot(aes(x = xx, ydist = .value)) + \n  stat_pointinterval() + \n  geom_abline(intercept = 0, slope = 1)\n```\n\n::: {.cell-output-display}\n![imputed values (y axis) vs the real values (x axis), and the 1:1 line for comparison. The posterior distributions are close to the truth, because the regression equation lets information flow in both directions.](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nposterior_and_original |> \n  ggplot(aes(xdist = .value, y = yy)) + \n  stat_pointinterval() + \n  geom_point(aes(x = xx, y = yy), \n             col = \"red\",\n             inherit.aes = FALSE,\n             data = tibble(\n               xx = xx[which(!is.na(xx2))],\n               yy = yy[which(!is.na(xx2))]\n               ))\n```\n\n::: {.cell-output-display}\n![The original relationship, with posterior distributions for missing x variables.](index_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\nThe major takeaway from this model is that once we have created our merged parameter and data vector `x`, within the `transformed parameters` block, we can use it just like a vector made entirely of observations. The model structure causes information to \"flow both ways\" and automatically gives us the posterior distribution that is most consistent with our data and model. From the point of view of the model, there is no difference between a missing observation and any other unknown number, like a standard deviation or average.\n\nI also enjoy that we are modelling an average for the independent $x$ variable -- and then using that parameter to center the vector before modelling! This is useful if you want to set a prior on the intercept for what the average X value should be.  Normally it would be tricky to center a variable with missing data (if you don't know all the values, how can you know their average?) but Bayes makes it effortless.\n\n## Count data with missing numbers\n\nTo extend this model further, I want to try modelling count data for both an independent and dependent variable.\n\nIn this example, there will be missing data an independent variable. However, we're not going to be able to model the missing counts as _counts_, because Stan does not allow discrete missing data. Instead we'll treat the unobserved data as lognormal, and see how wrong we are.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}